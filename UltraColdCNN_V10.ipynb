{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import keras.backend as K\n",
    "from keras.backend import int_shape\n",
    "import tensorflow_addons as tfa\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training data from results folder\n",
    "savepath = './results/'\n",
    "trainin = pkl.load(open(savepath + \"trainin\", \"rb\"))\n",
    "trainout = pkl.load(open(savepath + \"trainout\", \"rb\"))\n",
    "testin = pkl.load(open(savepath + \"realdatain\", \"rb\"))\n",
    "testout = pkl.load(open(savepath + \"realdataout_s\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking shapes of input data. Should be like (Number of samples, Number of features)\n",
    "print(trainin.shape)\n",
    "print(trainout.shape)\n",
    "print(testin.shape)\n",
    "print(testout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers 1.5 times greater than fifth sextile or less than first sextile of all pixel brightness\n",
    "def RemoveOutliers(inputs):\n",
    "    quants = tfp.stats.quantiles(inputs, num_quantiles=6)\n",
    "    iqr = quants[5] - quants[1]\n",
    "    upper = quants[5] + K.constant(1.5) * iqr\n",
    "    lower = quants[1] - K.constant(1.5) * iqr\n",
    "    zeros = K.zeros_like(inputs)\n",
    "    outputs = K.switch(K.greater(inputs, upper), zeros, inputs)\n",
    "    outputs = K.switch(K.less(inputs, lower), zeros, outputs)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of all pixels across a batch\n",
    "def NormalizeBatch(inputs):\n",
    "    mean = tf.math.reduce_mean(inputs)\n",
    "    stdv = tf.math.reduce_std(inputs)\n",
    "    \n",
    "    return (inputs-mean)/stdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input and output sizes\n",
    "input_size = trainin.shape[1] #Input dimensions to model\n",
    "output_size = trainout.shape[1] #Output dimensions to model\n",
    "\n",
    "#ML Hyperparameters\n",
    "epochs = 150 #number of passes of the data\n",
    "batchsize = 1 #number of images fed in at a time\n",
    "steps_per_epoch = 500\n",
    "version = 2 #model version number if same hyperparameters\n",
    "iterations = trainin.shape[0]//batchsize #number of batches used per epoch\n",
    "initial_lr = 10e-4\n",
    "decay_rate = 0.75 #Decay rate of the learning rate\n",
    "lr_decay = (1. / decay_rate - 1) / 2500\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=10e-4, epsilon=2e-2) #ML optimizer\n",
    "metric =  keras.metrics.MeanSquaredError() #metric to be used for training\n",
    "val_metric = keras.metrics.MeanSquaredError() #metric to be used for validation\n",
    "\n",
    "#Configuration dictionary for ML model\n",
    "config = {'act1': 'relu', 'act2': 'linear', 'act3': 'softmax'}\n",
    "\n",
    "#Layer Dimensions\n",
    "lstm_size = 8 #Number of lstm nodes in seq2seq block\n",
    "conv_size = 8 #Number of convolutional layers at the start of each conv block\n",
    "final_size = 1 #Number of output layers in conv block (Increasing this exponentially scales processing time)\n",
    "dense_size = 128 #Number of dense layers at the end of the model unrolling the key features\n",
    "\n",
    "#Convolutional block made up of three sub-blocks concatenated according to \"order\"\n",
    "def ConvBlock(inputs, order):\n",
    "    ConvBlock1 = keras.Sequential()\n",
    "    ConvBlock1.add(Conv2D(conv_size, \n",
    "                          kernel_size=2, \n",
    "                          padding='same', \n",
    "                          data_format='channels_first', \n",
    "                          activation=config['act1']))\n",
    "    ConvBlock1.add(BatchNormalization())\n",
    "    ConvBlock1.add(Conv2D(final_size, \n",
    "                          kernel_size=2, \n",
    "                          padding='same', \n",
    "                          data_format='channels_first', \n",
    "                          activation=config['act1']))\n",
    "    ConvBlock1.add(SpatialDropout2D(0.4, data_format='channels_first'))\n",
    "    ConvBlock1.add(tfa.layers.InstanceNormalization())\n",
    "    ConvBlock1.add(Reshape((final_size, 24, 49, 1)))\n",
    "    \n",
    "    ConvBlock2 = keras.Sequential()\n",
    "    ConvBlock2.add(Conv2D(conv_size, \n",
    "                          kernel_size=3, \n",
    "                          padding='same', \n",
    "                          data_format='channels_first', \n",
    "                          activation=config['act1']))\n",
    "    ConvBlock2.add(BatchNormalization())\n",
    "    ConvBlock2.add(Conv2D(final_size, \n",
    "                          kernel_size=3, \n",
    "                          padding='same', \n",
    "                          data_format='channels_first',\n",
    "                          activation=config['act1']))\n",
    "    ConvBlock2.add(SpatialDropout2D(0.4, data_format='channels_first'))\n",
    "    ConvBlock2.add(tfa.layers.InstanceNormalization())\n",
    "    ConvBlock2.add(Reshape((final_size, 24, 49, 1)))\n",
    "    \n",
    "    ConvBlock3 = keras.Sequential()\n",
    "    ConvBlock3.add(Conv2D(conv_size, \n",
    "                          kernel_size=5, \n",
    "                          padding='same', \n",
    "                          data_format='channels_first', \n",
    "                          activation=config['act1']))\n",
    "    ConvBlock3.add(BatchNormalization())\n",
    "    ConvBlock3.add(Conv2D(final_size, \n",
    "                          kernel_size=5, \n",
    "                          padding='same', \n",
    "                          data_format='channels_first', \n",
    "                          activation=config['act1']))\n",
    "    ConvBlock3.add(SpatialDropout2D(0.4, data_format='channels_first'))\n",
    "    ConvBlock3.add(tfa.layers.InstanceNormalization())\n",
    "    ConvBlock3.add(Reshape((final_size, 24, 49, 1)))\n",
    "    \n",
    "    if order==1:\n",
    "        ConvBlock = Concatenate(axis=4)((ConvBlock1(inputs), ConvBlock2(inputs), ConvBlock3(inputs)))\n",
    "    elif order==2:\n",
    "        ConvBlock = Concatenate(axis=4)((ConvBlock1(inputs), ConvBlock3(inputs), ConvBlock2(inputs)))\n",
    "    elif order==3:\n",
    "        ConvBlock = Concatenate(axis=4)((ConvBlock3(inputs), ConvBlock1(inputs), ConvBlock2(inputs)))\n",
    "    return ConvBlock\n",
    "\n",
    "inputs = keras.Input(shape=(input_size,), name='input') #Input layer\n",
    "# x = Lambda(RemoveOutliers)(inputs) #Lambda layer calling setting outlier values to 0\n",
    "# x = Masking(mask_value=0.0)(x) #Masking values equal to 0\n",
    "x = Reshape(target_shape=(1, 49, 49))(inputs) #Reshaping to add a channel dimension before the features\n",
    "x = AveragePooling2D(pool_size=(2, 1), data_format='channels_first')(x) #Averaging adjacent pixels to reduce number of significant features\n",
    "x = Lambda(NormalizeBatch)(x) #Normalizing all items in batch (Not using batchnorm because we want this to work the same for training and testing)\n",
    "\n",
    "#Creating covolutional block layers with each permutation of the sub-block order\n",
    "conv1 = ConvBlock(x, 1)\n",
    "conv2 = ConvBlock(x, 2)\n",
    "conv3 = ConvBlock(x, 3)\n",
    "\n",
    "#The first Seq2Seq block with attention wrapped in two time-distributed layers. \n",
    "#Inputs to the model will look like (columns, convolutional sub-blocks)\n",
    "x = TimeDistributed(TimeDistributed(Bidirectional(LSTM(lstm_size, #Number of BLSTM nodes\n",
    "                                                       activation=config['act1'], #Activation function\n",
    "                                                       recurrent_dropout=0.4, #Occasionally forget relationship between memory cells during training\n",
    "                                                       dropout=0.4, #Occasionally forget memory cells during training\n",
    "                                                       return_sequences=True, #Will pass all lstm sequences to next LSTM layer\n",
    "                                                       return_state=False))))(conv1)\n",
    "x = TimeDistributed(TimeDistributed(BatchNormalization()))(x)\n",
    "y = TimeDistributed(TimeDistributed(Bidirectional(LSTM(lstm_size, \n",
    "                                                       activation=config['act1'], \n",
    "                                                       recurrent_dropout=0.4, \n",
    "                                                       dropout=0.4, \n",
    "                                                       return_sequences=True))))(x)\n",
    "y = TimeDistributed(TimeDistributed(BatchNormalization()))(y) #Batch normalize the convolutional filters for each column\n",
    "attention = TimeDistributed(TimeDistributed(Dot(axes=[2, 2])))([y, x]) #Dot product attention mechanism creates weighting of features\n",
    "attention = TimeDistributed(TimeDistributed(Activation(config['act3'])))(attention)\n",
    "context = TimeDistributed(TimeDistributed(Dot(axes=[2, 1])))([attention, x])\n",
    "context = TimeDistributed(TimeDistributed(BatchNormalization()))(context)\n",
    "dcc1 = Concatenate()([context, y])\n",
    "\n",
    "x = TimeDistributed(TimeDistributed(Bidirectional(LSTM(lstm_size, activation=config['act1'], recurrent_dropout=0.4, dropout=0.4, return_sequences=True, return_state=False))))(conv2)\n",
    "x = TimeDistributed(TimeDistributed(BatchNormalization()))(x)\n",
    "y = TimeDistributed(TimeDistributed(Bidirectional(LSTM(lstm_size, activation=config['act1'], recurrent_dropout=0.4, dropout=0.4, return_sequences=True))))(x)\n",
    "y = TimeDistributed(TimeDistributed(BatchNormalization()))(y)\n",
    "attention = TimeDistributed(TimeDistributed(Dot(axes=[2, 2])))([y, x])\n",
    "attention = TimeDistributed(TimeDistributed(Activation(config['act3'])))(attention)\n",
    "context = TimeDistributed(TimeDistributed(Dot(axes=[2, 1])))([attention, x])\n",
    "context = TimeDistributed(TimeDistributed(BatchNormalization()))(context)\n",
    "dcc2 = Concatenate()([context, y])\n",
    "\n",
    "x = TimeDistributed(TimeDistributed(Bidirectional(LSTM(lstm_size, activation=config['act1'], recurrent_dropout=0.4, dropout=0.4, return_sequences=True, return_state=False))))(conv3)\n",
    "x = TimeDistributed(TimeDistributed(BatchNormalization()))(x)\n",
    "y = TimeDistributed(TimeDistributed(Bidirectional(LSTM(lstm_size, activation=config['act1'], recurrent_dropout=0.4, dropout=0.4, return_sequences=True))))(x)\n",
    "y = TimeDistributed(TimeDistributed(BatchNormalization()))(y)\n",
    "attention = TimeDistributed(TimeDistributed(Dot(axes=[2, 2])))([y, x])\n",
    "attention = TimeDistributed(TimeDistributed(Activation(config['act3'])))(attention)\n",
    "context = TimeDistributed(TimeDistributed(Dot(axes=[2, 1])))([attention, x])\n",
    "context = TimeDistributed(TimeDistributed(BatchNormalization()))(context)\n",
    "dcc3 = Concatenate()([context, y])\n",
    "\n",
    "decoder_combined_context = Concatenate()([dcc1, dcc2, dcc3]) #Concatenate Seq2Seq block outputs\n",
    "\n",
    "#Fully connected block that gradually unrolls Columns -> Rows -> Convolutional filter nodes\n",
    "y = TimeDistributed(TimeDistributed(Flatten()))(decoder_combined_context)\n",
    "y = Dense(dense_size, activation=config['act1'])(y)\n",
    "y = TimeDistributed(Flatten())(y)\n",
    "y = Dense(dense_size, activation=config['act1'])(y)\n",
    "y = Flatten()(y)\n",
    "y = Dense(dense_size, activation=config['act1'])(y)\n",
    "\n",
    "main_output = Dense(output_size, activation=config['act2'], name='main_output')(y)#Output layer\n",
    "\n",
    "#Assemble model\n",
    "model = keras.Model(inputs=inputs, outputs = main_output)\n",
    "modelname = (\"GatedCNN_%.1e_%d_%d_%d\" % (initial_lr, epochs, batchsize, version))\n",
    "#PNG image of model structure\n",
    "keras.utils.plot_model(model, 'GatedCNN.png', show_shapes=True)\n",
    "checkpoint = ModelCheckpoint(savepath + \"GatedCNN_weights.hdf5\", monitor=\"val_loss\", verbose=1,\n",
    "    save_best_only=True, mode=\"auto\", save_freq=\"epoch\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics='mae'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model.fit(trainin, \n",
    "          trainout, \n",
    "          batch_size=batchsize, \n",
    "          epochs=epochs, \n",
    "          verbose=1, \n",
    "          validation_data=(testin, testout),\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          callbacks=[checkpoint],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.load_weights(savepath + \"GatedCNN_weights.hdf5\")\n",
    "model.save(\"./results/%s.h5\" % (modelname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
